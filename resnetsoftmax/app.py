"""
app.py for ResNet-18 + Softmax Classifier

- Loads the pre-trained ResNet-18 model for feature extraction.
- Loads the trained Softmax classifier (W, b, mean, std) from 'softmax_model_resnet.pkl'.
- Provides a Streamlit interface for users to upload an image and get a prediction.
- This app is specifically designed to work with the model trained by 'feature_2_resnet.py'.
"""

import streamlit as st
import pickle
import numpy as np
import os
import torch
from torchvision import transforms
from torchvision.models import resnet18, ResNet18_Weights
from PIL import Image

# =======================
# 1. Cáº¥u hÃ¬nh & Táº£i mÃ´ hÃ¬nh
# =======================
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# --- Sá»¬A Lá»–I: Sá»­ dá»¥ng Ä‘Æ°á»ng dáº«n tuyá»‡t Ä‘á»‘i Ä‘á»ƒ Ä‘áº£m báº£o luÃ´n tÃ¬m tháº¥y tá»‡p ---
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
MODEL_PATH = os.path.join(SCRIPT_DIR, "outputs", "softmax_model_resnet.pkl")


@st.cache_resource
def load_models():
    """Táº£i mÃ´ hÃ¬nh ResNet-18 vÃ  mÃ´ hÃ¬nh Softmax Ä‘Ã£ huáº¥n luyá»‡n."""
    # 1. Táº£i mÃ´ hÃ¬nh ResNet-18 Ä‘á»ƒ trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng
    weights = ResNet18_Weights.IMAGENET1K_V1
    transform_for_resnet = weights.transforms()
    resnet_model = resnet18(weights=weights).to(DEVICE)

    # Loáº¡i bá» lá»›p phÃ¢n loáº¡i cuá»‘i cÃ¹ng cá»§a ResNet Ä‘á»ƒ láº¥y Ä‘áº·c trÆ°ng
    resnet_model.fc = torch.nn.Identity()
    resnet_model.eval()

    # 2. Táº£i mÃ´ hÃ¬nh Softmax Ä‘Ã£ huáº¥n luyá»‡n
    if not os.path.exists(MODEL_PATH):
        st.error(f"Lá»—i: KhÃ´ng tÃ¬m tháº¥y tá»‡p mÃ´ hÃ¬nh táº¡i '{MODEL_PATH}'.")
        st.info("HÃ£y cháº¯c cháº¯n ráº±ng báº¡n Ä‘Ã£ cháº¡y tá»‡p 'feature_2_resnet.py' thÃ nh cÃ´ng.")
        return None, None, None, None, None, None, None

    with open(MODEL_PATH, "rb") as f:
        softmax_model = pickle.load(f)

    W = softmax_model["W"]
    b = softmax_model["b"]
    feature_mean = softmax_model["mean"]
    feature_std = softmax_model["std"]

    # --- Sá»¬A Lá»–I KeyError: Táº¡o má»™t báº£n Ä‘á»“ ngÆ°á»£c Ä‘á»ƒ tra cá»©u tÃªn nhÃ£n tá»« chá»‰ sá»‘ ---
    label_map = softmax_model["label_map"]
    # original label_map: {"non-phone": 0, "defective": 1, ...}
    # reversed_label_map: {0: "non-phone", 1: "defective", ...}
    reversed_label_map = {v: k for k, v in label_map.items()}

    return resnet_model, transform_for_resnet, W, b, feature_mean, feature_std, reversed_label_map


# Táº£i táº¥t cáº£ cÃ¡c mÃ´ hÃ¬nh vÃ  dá»¯ liá»‡u cáº§n thiáº¿t
resnet_model, transform_for_resnet, W, b, feature_mean, feature_std, reversed_label_map = load_models()


# =======================
# 2. CÃ¡c hÃ m xá»­ lÃ½
# =======================
def extract_resnet_features(pil_image, model, transform, device):
    """TrÃ­ch xuáº¥t vector Ä‘áº·c trÆ°ng tá»« áº£nh PIL báº±ng ResNet-18."""
    if pil_image.mode != "RGB":
        pil_image = pil_image.convert("RGB")

    img_t = transform(pil_image)
    batch_t = torch.unsqueeze(img_t, 0).to(device)

    with torch.no_grad():
        features = model(batch_t)

    return features.cpu().numpy()


def softmax(z):
    """TÃ­nh toÃ¡n hÃ m softmax."""
    if z.ndim == 1:
        z = z.reshape(1, -1)
    z = z - np.max(z, axis=1, keepdims=True)
    exp_z = np.exp(z)
    return exp_z / np.sum(exp_z, axis=1, keepdims=True)


def predict(X_feature):
    """Dá»± Ä‘oÃ¡n tá»« vector Ä‘áº·c trÆ°ng Ä‘Ã£ chuáº©n hÃ³a."""
    scores = X_feature @ W + b
    probs = softmax(scores)
    preds = np.argmax(probs, axis=1)
    return preds, probs


# =======================
# 3. Giao diá»‡n Streamlit
# =======================
st.title("PhÃ¢n loáº¡i áº£nh Ä‘iá»‡n thoáº¡i (ResNet-18 + Softmax)")
st.write(
    "á»¨ng dá»¥ng nÃ y sá»­ dá»¥ng mÃ´ hÃ¬nh ResNet-18 Ä‘á»ƒ trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng vÃ  má»™t bá»™ phÃ¢n loáº¡i Softmax Ä‘á»ƒ dá»± Ä‘oÃ¡n tráº¡ng thÃ¡i cá»§a Ä‘iá»‡n thoáº¡i.")

if resnet_model is None:
    st.stop()

uploaded_file = st.file_uploader("Táº£i lÃªn má»™t áº£nh Ä‘á»ƒ dá»± Ä‘oÃ¡n", type=["jpg", "png", "jpeg"])

if uploaded_file is not None:
    image = Image.open(uploaded_file)
    st.image(image, caption="áº¢nh báº¡n Ä‘Ã£ táº£i lÃªn", use_column_width=True)

    with st.spinner('Äang phÃ¢n tÃ­ch áº£nh... (sá»­ dá»¥ng GPU náº¿u cÃ³)'):
        # 1. TrÃ­ch xuáº¥t Ä‘áº·c trÆ°ng ResNet
        resnet_features = extract_resnet_features(image, resnet_model, transform_for_resnet, DEVICE)

        # 2. Chuáº©n hÃ³a Ä‘áº·c trÆ°ng
        standardized_features = (resnet_features - feature_mean) / feature_std

        # 3. Dá»± Ä‘oÃ¡n
        pred_class, probs = predict(standardized_features)

        st.write("---")
        st.subheader("ğŸ‰ Káº¿t quáº£ dá»± Ä‘oÃ¡n")

        predicted_label_index = pred_class[0]
        predicted_label_name = reversed_label_map.get(predicted_label_index, "KhÃ´ng xÃ¡c Ä‘á»‹nh")

        if predicted_label_name == "defective":
            st.error(f"ğŸ‘‰ Dá»± Ä‘oÃ¡n: {predicted_label_name.upper()} (Lá»—i)")
        elif predicted_label_name == "non-defective":
            st.success(f"ğŸ‘‰ Dá»± Ä‘oÃ¡n: {predicted_label_name.upper()} (KhÃ´ng lá»—i)")
        else:
            st.warning(f"ğŸ‘‰ Dá»± Ä‘oÃ¡n: {predicted_label_name.upper()}")

        st.subheader("ğŸ“Š XÃ¡c suáº¥t dá»± Ä‘oÃ¡n cho tá»«ng lá»›p:")
        for i in range(len(reversed_label_map)):
            class_name = reversed_label_map[i]
            st.write(f"- **{class_name}**: `{probs[0][i]:.4f}`")